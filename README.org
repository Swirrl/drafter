* Drafter

A RESTful Clojure web service to support PMD's admin tool in moving
data updates between draft and live triple stores.


* Getting started

- clone this project
- [[http://leiningen.org/#install][Install leiningen]]
- cd into the project directory =cd drafter=
- =lein repl= This will start an http server on port 3001

** Building and running

To run a dev build of the drafter server with configuration defaults
(port 3001 and a repo stored in ./drafter/repositories/db) simply run

=$ lein repl=

To run the tests from the console:

=$ lein test=

To run a test from a repl, make sure the test namespace is loaded (evaling it will usually do this) then run (for example):

#+BEGIN_SRC clojure
(clojure.test/run-tests 'drafter.routes.sparql-test)
#+END_SRC

To build:

=$ lein uberjar=

To run a built drafter server (without leiningen or a repl) on port 3001:

=$ java -jar target/drafter-0.1.0-SNAPSHOT-standalone.jar=

** Configuring Drafter

Drafter uses [[https://github.com/weavejester/environ][environ]] for its configuration.  This means it uses
environment variables (and/or java properties) to pass configuration
variables from the environment.

Configurable properties and their defaults are:

#+BEGIN_EXAMPLE
DRAFTER_HTTP_PORT:            (default 3001)
DRAFTER_REPO_PATH:            (default "drafter-db")
DRAFTER_INDEXES:              spoc,posc,cosp (Best for query performance, slowest for insert)
DRAFTER_BATCHED_WRITE_SIZE:   (default 10000)
#+END_EXAMPLE

Some examples of supplying these properties are provided below:

As environment variables via lein run:

#+BEGIN_SRC shell :exports code
$ env DRAFTER_HTTP_PORT=3040 DRAFTER_REPO_PATH=/var/drafter-db lein run
#+END_SRC

As java properties via a built application jar:

#+BEGIN_SRC shell :exports code
$ java -Ddrafter.http.port=3050 -Ddrafter.repo.path=./drafter-database -jar target/drafter-0.1.0-SNAPSHOT-standalone.jar
#+END_SRC

As environment variables via a built application jar:

#+BEGIN_SRC shell :exports code
$ env DRAFTER_HTTP_PORT=3050 DRAFTER_REPO_PATH=./drafter-database java -jar target/drafter-0.1.0-SNAPSHOT-standalone.jar
#+END_SRC

Indexes can be configured via the property =DRAFTER_INDEXES=, we use
the same default indexes as sesame. =spoc,posc,cosp= which covers all
possible

*** Configuring Logging

Logging on the JVM can be awkward due to Java's legacy, however we've
tried to keep it as simple as possible by supporting:

- Logging config via our log-config.edn file, which supports pure
  Clojure configuration (No XML or Log4J Property Files).
- Logging both Java and Clojure code (meaning it's easy to output
  sesame's log messages with the same config)
- A logging configuration fallback chain (log-config.edn -> default
  config in drafter.jar!log-config.edn)

This is achieved by through the use of various logging libraries:

- [[https://github.com/clojure/tools.logging][clojure.tools.logging]] with the [[http://logging.apache.org/log4j/2.x/][Log4J]] logging

- [[https://github.com/malcolmsparks/clj-logging-config][clj-logging-config]] for the configuration DSL to provide simple Log4J
  configuration to configure logging in different namespaces, Java
  packages and setup your own log appenders.

To configure logging in Drafter you should create a file called
=log-config.edn= by copying the example =log-config.edn.example=.

An example of a drafter =log-config.edn= file is here:

#+BEGIN_SRC clojure :exports code
(let [log-pattern "%d{ABSOLUTE} %-5p %.20c{1} %-10.10X{reqId} :: %m%n"]
       (set-loggers!
        ["org.openrdf" "drafter"]
        {:name "drafter"
         :level :trace
         :out (DailyRollingFileAppender.
               (EnhancedPatternLayout. log-pattern)
               "logs/drafter.log" "'.'YYYY-MM")}

        "drafter.rdf.sparql-protocol"
        {:name "sparql"
         :level :info
         :out (DailyRollingFileAppender.
               (EnhancedPatternLayout. log-pattern)
               "logs/sparql.log" "'.'YYYY-MM")}))
#+END_SRC

The first thing to note is that this [[https://github.com/edn-format/edn][edn]] file must contain a Clojure
form to be evaluated.

When drafter starts it first looks at the environment for a variable
called `LOG_CONFIG_FILE` if this is defined then the file at the
location is evaluated, and if no file is found then Drafter will
fallback to a file in its working directory named `log-config.edn`.
Finally if this file is not found then drafter will configure its
logging by using a default `log-config.edn` file contained in its Jar
file.

To configure the logging these forms should then contain a call to
[[https://github.com/malcolmsparks/clj-logging-config][clj-logging-config's]] =set-loggers!= macro.

** Docker

Successful drafter builds get built into docker images on dockerhub
(hub.docker.com) at =swirrl/drafter=.

*** Running the container

Suggested commands:

1. Pull the image

=docker pull swirrl/drafter:build_<build-number>=

2. Make a data container for the database

=docker run -d -v /data/drafter-database --name drafter-data ubuntu true=

3. Make a data container for the logs

=docker run -d -v /drafter/logs --name drafter-logs ubuntu true=

4. Run drafter itself

Depending on the server topology, you might want to do one of the following:

-  link the drafter container to a client container
-  expose a port to the host server (which you could proxy-to via nginx)
-  use an ambassador container to link over the network

e.g. (exposing a port to the host server)
=docker run -d -p 127.0.0.1:<port-to-expose-on-host>:3001 --volumes-from drafter-data --volumes-from drafter-logs --name drafter swirrl/drafter:build_xxx=

(check it's running with =docker ps=)

To backup the data
------------------
=docker run --volumes-from drafter-data -v <folder-on-the-host-to-backup-to>:/data-backup ubuntu tar cvf /data-backup/backup.tar /data/drafter-database=

Explanation: this

-  creates a new container based on =ubuntu= image,
-  mounts the data volume onto it
-  mounts a folder of your choice from the host system into
   =/data-backup= inside the container
-  inside the container, it tars contents of
   =/var/lib/drafter-database= (the mounted volume from
   =drafter-data=) into =/data-backup= volume (which will appear on
   the mounted host dir).

*** To backup the logs

Similarly to the data:

=docker run --volumes-from drafter-logs -v <folder-on-the-host-to-backup-to>:/logs-backup ubuntu tar cvf /logs-backup/backup.tar /drafter/logs=

*** To peek inside a running drafter docker container

This will get you a bash shell inside the running drafter docker container

=docker exec -i -t drafter bash=

** Drafter's SPARQL Endpoints

Drafter exposes a number of specialised SPARQL endpoints for querying they are:

=GET | POST /sparql/state?query=select * FROM...=

SPARQL endpoint on state graph only

=GET | POST /sparql/live?query=select * FROM...=

SPARQL endpoint on live union graph only (drafter to check state
graph on each request to know what this is).

=GET | POST /sparql/draft?graph=GURI1&graph=GURI2...&query=select * FROM...=

SPARQL endpoint on an arbitrary set of drafts (plus the rest from live).

If on the draft graph you want the drafts to be unioned with the
current state of the public live graphs then you should also pass the
HTTP parameter =&union-with-live=true=.  The default value for this is
false.

** Graph Management Operations
*** Create a new draft

| Verbs | Route           | Synchronous | Priority        |
|-------+-----------------+-------------+-----------------|
| POST  | =/draft/create= | Yes         | =0 :sync-write= |

This route synchronously creates a new draft and returns the =GURI=
(Graph URI) of the draft graph in its response object.

It accepts the following parameters:

| Parameter    | Required | Description                                                             |
|--------------+----------+-------------------------------------------------------------------------|
| =live-graph= | Yes      | The Graph URI of the live graph that this is a draft graph of.          |
| =meta-???=   | No       | Key/Value pair for metadata to attach to this draft in the state graph. |

#+BEGIN_SRC http :exports both
POST http://localhost:3001/draft/create?live-graph=http://swirrl.com/graph/mission-statement
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 200 OK
Date: Wed, 04 Mar 2015 17:20:59 GMT
Content-Length: 79
Content-Type: application/json; charset=utf-8
Server: Jetty(7.6.13.v20130916)

{
  "guri": "http:\/\/publishmydata.com\/graphs\/drafter\/draft\/c1026ac2-81cf-4aa8-97d5-5eb945ef03a5",
  "type": "ok"
}
#+end_example

*** Append a draft with graph with triples from a file

| Verbs | Route    | Synchronous | Priority           |
|-------+----------+-------------+--------------------|
| POST  | =/draft= | No          | =1 :batched-write= |

Asynchronously schedules a request to append or replace the specified
draft graph with the contents of the provided RDF file.

Enqueues an append of the contents of the draft graph with the file
data.

It accepts the following parameters:

| Parameter  | Required | Description                                                                                                                  |
|------------+----------+------------------------------------------------------------------------------------------------------------------------------|
| =graph=    | Yes      | The URI of the draft graph you wish to append/replace into.                                                                  |
| =meta-???= | No       | Key/Value pair of metadata to attach to this draft in the state graph.  It will be applied with the batched write operation. |

Must contain the file of triples with a correct mime-type.

The file must be supplied as multi-part-form data under the key =file=.

Returns a 202 if enqueued successfully, with a JSON response
containing a path segment for the client to poll for the status of the
job.

#+BEGIN_SRC http :exports both
POST http://localhost:3001/draft?graph=http://publishmydata.com/graphs/drafter/draft/c1026ac2-81cf-4aa8-97d5-5eb945ef03a5
Content-Type: multipart/form-data; boundary=AaB03x

--AaB03x
Content-Disposition: form-data; name="file"; filename="mission-statement.nt"
Content-Type: application/n-triples

<http://swirrl.com/mission-statement> <http://swirrl.com/published-facts> 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 .
--AaB03x--
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 202 Accepted
Date: Wed, 04 Mar 2015 17:20:59 GMT
Content-Length: 79
Content-Type: application/json; charset=utf-8
Server: Jetty(7.6.13.v20130916)

{
"type": "ok",
"id": "/status/finished-jobs/2b9b5c60-f5f7-4141-b21f-592886b98791"
}
#+end_example

*** Replace a draft with graph with triples from a file

| Verbs | Route    | Synchronous | Priority           |
|-------+----------+-------------+--------------------|
| PUT   | =/draft= | No          | =1 :batched-write= |

Asynchronously schedules a request to append or replace the specified
draft graph with the contents of the provided RDF file.

Enqueues a replace of the contents of the draft graph with the file
data.

It accepts the following parameters:

| Parameter  | Required | Description                                                                                                                  |
|------------+----------+------------------------------------------------------------------------------------------------------------------------------|
| =graph=    | Yes      | The URI of the draft graph you wish to append/replace into.                                                                  |
| =meta-???= | No       | Key/Value pair of metadata to attach to this draft in the state graph.  It will be applied with the batched write operation. |

Must contain the file of triples with a correct mime-type.

The file must be supplied as multi-part-form data under the key =file=.

Returns a 202 if enqueued successfully, with a JSON response
containing a path segment for the client to poll for the status of the
job.

#+BEGIN_SRC http :exports both
PUT http://localhost:3001/draft?graph=http://publishmydata.com/graphs/drafter/draft/c1026ac2-81cf-4aa8-97d5-5eb945ef03a5
Content-Type: multipart/form-data; boundary=AaB03x

--AaB03x
Content-Disposition: form-data; name="file"; filename="mission-statement.nt"
Content-Type: application/n-triples

<http://swirrl.com/mission-statement> <http://swirrl.com/published-facts> 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 .
--AaB03x--
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 202 Accepted
Date: Wed, 04 Mar 2015 17:20:59 GMT
Content-Length: 79
Content-Type: application/json; charset=utf-8
Server: Jetty(7.6.13.v20130916)

{
"type": "ok",
"id": "/status/finished-jobs/2b9b5c60-f5f7-4141-b21f-592886b98791"
}
#+end_example

*** Delete a draft or live graph

| Verbs  | Route    | Synchronous | Priority                                   |
|--------+----------+-------------+--------------------------------------------|
| DELETE | =/graph= | No          | =1 :batched-write= or =2 :exclusive-write= |

Enqueues a delete of the specified graph, which can either be a live
graph or a draft graph URI.  If the graph is a draft graph it will be
removed as a =:batched-write=, if the graph is a live graph it will be
removed as an =:exclusive-write=.

As part of this operation all information from the state graph is
removed.

It accepts the following parameters:

| Parameter | Required | Description                                                   |
|-----------+----------+---------------------------------------------------------------|
| =graph=   | Yes      | The URI of the graph (live or draft) that you wish to delete. |


Returns a 202 if enqueued successfully, with the =queue-id= in the
response body:

#+BEGIN_SRC http :exports both
DELETE http://localhost:3001/graph?graph=http://publishmydata.com/graphs/drafter/draft/c1026ac2-81cf-4aa8-97d5-5eb945ef03a5
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 202 Accepted
Date: Wed, 04 Mar 2015 17:20:59 GMT
Content-Length: 79
Content-Type: application/json; charset=utf-8
Server: Jetty(7.6.13.v20130916)

{"type":"ok","id":"/status/finished-jobs/684bb438-09a8-418b-9537-6ce7e6d2f0ee"}
#+end_example

*** Making a draft live

| Verbs  | Route         | Synchronous | Priority             |
|--------+---------------+-------------+----------------------|
| DELETE | =/graph/live= | No          | =2 :exclusive-write= |

Enqueues a transactional migration the specified graph(s) from draft
to live.

If you wish to make multiple graphs live at once, simply supply
multiple graph arguments, these should all be scheduled together to
occur in a single transaction e.g.

It accepts the following parameters:

| Parameter | Required | Description                                     |
|-----------+----------+-------------------------------------------------|
| =graph=   | Yes      | The Draft graph URI that you wish to make live. |

NOTE you can also supply any number of =&graph= parameters, and all
graphs will be made live within the same atomic transaction.

This replaces the content of the live graph with the draft one,
removing the draft afterwards.  It also sets the graphs isPublic
status to true.

Returns a 202 if enqueued successfully, with the =queue-id= in the
response body

#+BEGIN_SRC http :exports both
PUT http://localhost:3001/graph/live?graph=http://publishmydata.com/graphs/drafter/draft/20091554-af8b-46da-a04a-474db49e2166
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 202 Accepted
Date: Wed, 04 Mar 2015 17:20:59 GMT
Content-Length: 79
Content-Type: application/json; charset=utf-8
Server: Jetty(7.6.13.v20130916)

{
  "id": "\/status\/finished-jobs\/45d6d24f-18ca-46ca-8172-de8c8a99dd51",
  "type": "ok"
}
#+end_example

*** Dumps End Points

For each of its endpoints drafter supports a dumps endpoint, for
retrieving data in the requested graph serialisation.  The endpoints
are at the following locations:

| Verbs | Route         | Synchronous |
|-------+---------------+-------------|
| GET   | =/data/draft= | Yes         |
| GET   | =/data/live=  | Yes         |
| GET   | =/data/raw=   | Yes         |

Each of these endpoints supports a =graph-uri= parameter to specify
which graph you wish to retrieve the data for.

It accepts the following parameters:

| Parameter         | Required | Description                                                       |
|-------------------+----------+-------------------------------------------------------------------|
| =graph-uri=       | Yes      | The URI that you want a data dump of.                             |

Any supported graph serialisation can be selected by setting the
accept header to the desired mime/type e.g. =application/n-triples=.

Each of these endpoints should additionally support all of the
behaviours and options of the endpoints that they wrap.  This is most
relevant for the drafts endpoint.

#+BEGIN_SRC http :exports both
GET http://localhost:3001/data/live?graph-uri=http://example.org/graph/one
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 200 OK
Date: Wed, 04 Mar 2015 17:55:18 GMT
Content-Disposition: attachment; filename="one.nt"
Content-Type: application/n-triples
Content-Length: 0
Server: Jetty(7.6.13.v20130916)

... content ...
#+end_example

*** Draft Dumps End Point

The draft dumps endpoint is unlike the others in that it supports the
following additional options inherited from its query endpoint:

| Parameter         | Required | Description                                                       |
|-------------------+----------+-------------------------------------------------------------------|
| =graph=           | No       | Used to specify the draft set.  Supported on draft endpoint only. |
| =union-with-live= | No       | Supported on draft endpoint only                                  |

Unlike the others the draft endpoint should be given the live graph
URI along with =graph= parameters that specify the draft set.  NOTE
you can supply just the draft graph for the desired live graph.

#+BEGIN_SRC http :exports both
GET http://localhost:3001/data/draft?graph-uri=http://example.org/graph/one&graph=http://example.org/graph/one
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 200 OK
Date: Wed, 04 Mar 2015 17:55:30 GMT
Content-Disposition: attachment; filename="one.nt"
Content-Type: application/n-triples
Content-Length: 0
Server: Jetty(7.6.13.v20130916)

... content ...
#+end_example

*** Polling for finished jobs

| Verbs | Route                         | Synchronous |
|-------+-------------------------------+-------------|
| GET   | =/status/finished-jobs/:uuid= | Yes         |

This route takes no query parameters.

When the job has finished the route will return a =200 OK= response
along with a success or error object associated with the job.

#+BEGIN_SRC http :results both
GET http://localhost:3001/status/finished-jobs/684bb438-09a8-418b-9537-6ce7e6d2f0ee
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 200 OK
Date: Wed, 04 Mar 2015 18:00:12 GMT
Content-Length: 13
Content-Type: application/json; charset=utf-8
Server: Jetty(7.6.13.v20130916)

{"type":"ok"}
#+end_example

In the case where the job is enqueued or is being processed i.e. it is
unfinished this route will return a 404:

#+BEGIN_SRC http :results both
GET http://localhost:3001/status/finished-jobs/711b438-09a8-418b-9537-6ce7e6d2faaa
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 404 Not Found
Date: Wed, 04 Mar 2015 18:08:45 GMT
Content-Length: 67
Content-Type: application/json; charset=utf-8
Server: Jetty(7.6.13.v20130916)

{"type":"not-found","message":"The specified job-id was not found"}
#+end_example

*** Querying the write-lock status

| Verbs | Route                    | Synchronous |
|-------+--------------------------+-------------|
| GET   | =/status/writes-locked/= | Yes         |

This route returns the boolean result indicating whether writes are
exclusively locked.

#+BEGIN_SRC http
GET http://localhost:3001/status/writes-locked
#+END_SRC

#+RESULTS:
#+begin_example
HTTP/1.1 200 OK
Date: Thu, 05 Mar 2015 00:38:15 GMT
Content-Type: text/html;charset=UTF-8
Content-Length: 5
Server: Jetty(7.6.13.v20130916)

false
#+end_example

*** TODO Add restart id to finished-jobs route
** Data Model

This is an alternative model to that written up by Ric.  It is
also different from what I was originally pitching.  The
key difference is that it models both live and draft graphs.
Whilst you can get away with less, Ric was right doing so feels
unnatural and asymetrical.  Hopefully this approach is intuitive
and symetrical!

In the db, we'll have a (private) 'state' graph which stores
details of the state of each graph.  The state graph and all
other graphs will be stored within the same triple store.
Some points to note about this approach:

- A hasDraft predicate associates a live graph with many drafts.
- The union of all live graphs can be obtained with the query:

#+BEGIN_SRC sparql :exports code
  SELECT ?live WHERE {
     ?live a drafter:ManagedGraph ;
             drafter:isPublic true .
  }
#+END_SRC

- When drafts are migrated into the "live" graph their entries
  and associations are removed from the state graph.

- The is:Public boolean lets you toggle whether the "live" graph
  is actually online and publicly accessible, and do so
  independently of creating a new graph.

#+BEGIN_SRC ttl
      <http://example.org/graph/live/1>
         a            drafter:ManagedGraph ;
         <created-at> "DateTime" ;
         <isPublic>  false ;
         <hasDraft> <http://drafter.swirrl.com/draft/graph/GUID-123> ;
                        a drafter:DraftGraph ;
                        <owner> "bob" ;
                        <updated-at> "DateTime" .
         <hasDraft> <http://drafter.swirrl.com/draft/graph/GUID-124> ;
                        a drafter:DraftGraph ;
                        <owner> "joe" ;
                        <updated-at> "DateTime" .

      # this is a graph with no draft changes
      <http://example.org/graph/live/1>
         a            drafter:ManagedGraph ;
         <isPublic>  true ;
         <created-at> "DateTime" .
#+END_SRC

** Other notes

Drafter doesn't know the difference between metadata graphs
and data graphs. It just moves data around and between states.
That's up to PMD to orchestrate.
